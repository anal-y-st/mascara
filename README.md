# Mask Learning Tool üß©

Outil l√©ger et extensible pour **entra√Æner** et **√©valuer** des mod√®les de vision (construction de masques, r√©gression/segmentation), en laissant **l'utilisateur g√©rer ses DataLoader**.

## ‚ú® Points cl√©s
- Mod√®les plug-and-play (registre de mod√®les).
- Entra√Ænement g√©n√©rique (m√©lange Huber/R2/SSIM, AMP optionnel, early stopping, scheduler).
- Visualisations par epoch (GT / Pred / Diff), courbes de m√©triques et **rapport automatique** (`report.json` + `report.md`).
- Config YAML + **override** en ligne de commande (`--set training.epochs=50 --set training.lr=1e-5`).
- Agnostique aux donn√©es : vous fournissez un module avec `get_loaders(...)` qui retourne vos DataLoader et stats.

## üöÄ Installation
```bash
pip install -r requirements.txt
# (optionnel) installation locale
pip install -e .
```

## üß™ D√©marrage rapide
1) Adaptez l'exemple de loader dans `examples/loader_template.py` √† vos donn√©es.
2) Lancez l'entra√Ænement :
```bash
python scripts/train.py   --config configs/swin_unet.yaml   --loaders examples.loader_template:get_loaders   --set training.epochs=5 --set training.outdir=results_demo
```
3) √âvaluation (recharge le best checkpoint) :
```bash
python scripts/evaluate.py   --config configs/swin_unet.yaml   --loaders examples.loader_template:get_loaders   --checkpoint results_demo/best_model.pth
```

## üß© Fournir vos DataLoader
Votre module doit exposer une fonction :
```python
def get_loaders(config: dict):
    """
    Retourne
      - train_loader (torch.utils.data.DataLoader)
      - val_loader   (torch.utils.data.DataLoader)
      - stats: dict avec les clefs suivantes
          input_mean, input_std, label_mean, label_std (scalaires ou arrays broadcastables)
    """
    return train_loader, val_loader, {
        "input_mean": 0.0, "input_std": 1.0,
        "label_mean": 0.0, "label_std": 1.0
    }
```
Pour un probl√®me de **segmentation/r√©gression par pixel**, les tenseurs `y` sont attendus de forme `[B, 1, H, W]`.

## ‚öôÔ∏è Override de config en CLI
- `--set a.b.c=value` met √† jour r√©cursivement la config (types inf√©r√©s : `true/false/int/float`).
- Exemples :
  - `--set training.lr=1e-4`
  - `--set model.embed_dim=96`
  - `--set training.amp=true --set training.early_stopping.patience=8`

## üì¶ R√©sultats produits
Dans `training.outdir` :
- `best_model.pth` (checkpoint meilleur R2)
- `history.json` (loss, R2, MAE, RMSE par epoch)
- `curves.png` (courbes d‚Äôapprentissage)
- `epoch_XX.png` (GT/Pred/Diff par epoch)
- `report.json` et `report.md` (r√©sum√© complet)

## üß± Ajouter un mod√®le
Ajoutez un fichier dans `models/` et enregistrez-le dans `models/registry.py`.

---

Made with ‚ù§Ô∏è for research & reproducibility.
